digraph {
	graph [size="12,12"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	2042784716256 [label="
 (4, 1)" fillcolor=darkolivegreen1]
	2042784380240 -> 2042784721296 [dir=none]
	2042784721296 [label="mat1
 (4, 16)" fillcolor=orange]
	2042784380240 -> 2042784743120 [dir=none]
	2042784743120 [label="mat2
 (16, 1)" fillcolor=orange]
	2042784380240 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :        (4, 16)
mat1_sym_strides:        (16, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :        (16, 1)
mat2_sym_strides:        (1, 16)"]
	2042438670688 -> 2042784380240
	2042784728400 [label="output_layer.bias
 (1)" fillcolor=lightblue]
	2042784728400 -> 2042438670688
	2042438670688 [label=AccumulateGrad]
	2042784379712 -> 2042784380240
	2042784379712 -> 2042784716816 [dir=none]
	2042784716816 [label="result
 (4, 16)" fillcolor=orange]
	2042784379712 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2042784379520 -> 2042784379712
	2042784379520 -> 2042784722016 [dir=none]
	2042784722016 [label="mat1
 (4, 32)" fillcolor=orange]
	2042784379520 -> 2042784722256 [dir=none]
	2042784722256 [label="mat2
 (32, 16)" fillcolor=orange]
	2042784379520 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :        (4, 32)
mat1_sym_strides:        (32, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (32, 16)
mat2_sym_strides:        (1, 32)"]
	2042784369824 -> 2042784379520
	2042784727920 [label="fully_conn_2.bias
 (16)" fillcolor=lightblue]
	2042784727920 -> 2042784369824
	2042784369824 [label=AccumulateGrad]
	2042784379808 -> 2042784379520
	2042784379808 -> 2042784722816 [dir=none]
	2042784722816 [label="result
 (4, 32)" fillcolor=orange]
	2042784379808 [label="ReluBackward0
----------------------
result: [saved tensor]"]
	2042784564224 -> 2042784379808
	2042784564224 -> 2042784722096 [dir=none]
	2042784722096 [label="mat1
 (4, 64)" fillcolor=orange]
	2042784564224 -> 2042784723056 [dir=none]
	2042784723056 [label="mat2
 (64, 32)" fillcolor=orange]
	2042784564224 [label="AddmmBackward0
--------------------------------
alpha           :              1
beta            :              1
mat1            : [saved tensor]
mat1_sym_sizes  :        (4, 64)
mat1_sym_strides:        (64, 1)
mat2            : [saved tensor]
mat2_sym_sizes  :       (64, 32)
mat2_sym_strides:        (1, 64)"]
	2042784373040 -> 2042784564224
	2042784727440 [label="fully_conn_1.bias
 (32)" fillcolor=lightblue]
	2042784727440 -> 2042784373040
	2042784373040 [label=AccumulateGrad]
	2042784563696 -> 2042784564224
	2042784563696 [label="CatBackward0
------------
dim: 1"]
	2042784564416 -> 2042784563696
	2042784564416 -> 2042351990768 [dir=none]
	2042351990768 [label="indices
 (4)" fillcolor=orange]
	2042784564416 [label="EmbeddingBackward0
------------------------------------
indices             : [saved tensor]
padding_idx         :     4294967295
scale_grad_by_freq  :          False
sparse              :          False
weight_sym_argsize_0:            610"]
	2042784367616 -> 2042784564416
	2042784562896 [label="users_embedding.weight
 (610, 32)" fillcolor=lightblue]
	2042784562896 -> 2042784367616
	2042784367616 [label=AccumulateGrad]
	2042784564272 -> 2042784563696
	2042784564272 -> 2042351990688 [dir=none]
	2042351990688 [label="indices
 (4)" fillcolor=orange]
	2042784564272 [label="EmbeddingBackward0
------------------------------------
indices             : [saved tensor]
padding_idx         :     4294967295
scale_grad_by_freq  :          False
sparse              :          False
weight_sym_argsize_0:           9724"]
	2042784374432 -> 2042784564272
	2042351977648 [label="movies_embedding.weight
 (9724, 32)" fillcolor=lightblue]
	2042351977648 -> 2042784374432
	2042784374432 [label=AccumulateGrad]
	2042784563792 -> 2042784564224
	2042784563792 [label=TBackward0]
	2042784380432 -> 2042784563792
	2042784727200 [label="fully_conn_1.weight
 (32, 64)" fillcolor=lightblue]
	2042784727200 -> 2042784380432
	2042784380432 [label=AccumulateGrad]
	2042784563648 -> 2042784379520
	2042784563648 [label=TBackward0]
	2042784373328 -> 2042784563648
	2042784727680 [label="fully_conn_2.weight
 (16, 32)" fillcolor=lightblue]
	2042784727680 -> 2042784373328
	2042784373328 [label=AccumulateGrad]
	2042784381536 -> 2042784380240
	2042784381536 [label=TBackward0]
	2042784372080 -> 2042784381536
	2042784728160 [label="output_layer.weight
 (1, 16)" fillcolor=lightblue]
	2042784728160 -> 2042784372080
	2042784372080 [label=AccumulateGrad]
	2042784380240 -> 2042784716256
}
