{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RecSys\n",
    "Modelo do tipo recuperação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando Tensor Board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/movie-lens')\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurando dispositivo para utilizar GPU se possível; caso contrário, CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mode = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(mode)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando dados do Movie Lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLens(Dataset):\n",
    "    '''\n",
    "    Classe criada com o intuito de ajustar o dataset pandas ao\n",
    "    treinamento de modelos utilizando o PyTorch, especialmente do que se\n",
    "    diz respeito à utilização de lotes (batches) durante o treinamento.\n",
    "    '''\n",
    "    def __init__(self, dataset_path: str, device: torch.device):\n",
    "        \"\"\"\n",
    "        Construtor da classe, responsável por ler os dados e organizar os dados\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "\n",
    "        dataset = pd.read_csv(dataset_path, decimal='.')\n",
    "\n",
    "        self.user_encoder = preprocessing.LabelEncoder()\n",
    "        self.users = self.user_encoder.fit_transform(dataset['userId'].values)\n",
    "\n",
    "        self.movie_encoder = preprocessing.LabelEncoder()\n",
    "        self.movies = self.movie_encoder.fit_transform(dataset['movieId'].values)\n",
    "        self.ratings = dataset['rating'].values\n",
    "\n",
    "        self.n_unique_users = len(np.unique(self.users))\n",
    "        self.n_unique_movies = len(np.unique(self.movies))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        \"\"\"\n",
    "        Retorna o número de avaliações do conjunto de dados\n",
    "        \"\"\"\n",
    "        return self.ratings.shape[0]\n",
    "\n",
    "    def __getitem__(self, item) -> dict[torch.tensor]:\n",
    "        \"\"\"\n",
    "        Retorna itens do conjunto de dados em lotes\n",
    "        \"\"\"\n",
    "        users = self.users[item]\n",
    "        movies = self.movies[item]\n",
    "        ratings = self.ratings[item]\n",
    "\n",
    "        return {\n",
    "            \"users\": torch.tensor(users, device=self.device, dtype=torch.long),\n",
    "            \"movies\": torch.tensor(movies, device=self.device, dtype=torch.long),\n",
    "            \"ratings\": torch.tensor(ratings, device=self.device, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "    def get_original_user_id(self, users):\n",
    "        \"\"\"\n",
    "        Retorna o ID original do usuário\n",
    "        \"\"\"\n",
    "        return self.user_encoder.inverse_transform(users)\n",
    "    \n",
    "    def get_original_movie_id(self, movies):\n",
    "        \"\"\"\n",
    "        Retorna o ID original do filme\n",
    "        \"\"\"\n",
    "        return self.movie_encoder.inverse_transform(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movie_lens = MovieLens('./data/movie-lens/raw/ratings.csv', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    0.265957\n",
       "3.0    0.198808\n",
       "5.0    0.131015\n",
       "3.5    0.130271\n",
       "4.5    0.084801\n",
       "2.0    0.074884\n",
       "2.5    0.055040\n",
       "1.0    0.027877\n",
       "1.5    0.017762\n",
       "0.5    0.013586\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(df_movie_lens.ratings).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividindo dataset entre conjunto de treinamento, validação e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_length = len(df_movie_lens)\n",
    "\n",
    "train_length = int(dataset_length * 0.7)\n",
    "valid_length = int(dataset_length * 0.15)\n",
    "test_length  = dataset_length - train_length - valid_length\n",
    "\n",
    "train_dataset, valid_dataset, test_dataset = torch.utils.data.random_split(\n",
    "    dataset=df_movie_lens,\n",
    "    lengths=(train_length, valid_length, test_length),\n",
    "    generator=generator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustando dataset para ser utilizado pelo PyTorch como um iterável que retorna lotes de dados a cada iteração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, generator=generator)\n",
    "validation_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após isso, toda vez que o DataLoader for requisitado, ele retornará um lote (batch) de 8 itens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users': tensor([131, 331, 599, 379], device='cuda:0'),\n",
       " 'movies': tensor([ 698,  686, 1004, 2038], device='cuda:0'),\n",
       " 'ratings': tensor([3, 4, 2, 3], device='cuda:0')}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "batch = next(dataiter)\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando modelo de RecSys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando modelo de RecSys no estilo de torre-dupla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieLensRecSys(nn.Module):\n",
    "    '''\n",
    "    Classe criada com o intuito de modelar a estrutura de torre-dupla,\n",
    "    isto é, um dos modelos clássicos de RecSys baseado em filtragem\n",
    "    colaborativa por meio de redes neurais.\n",
    "    '''\n",
    "    def __init__(self, n_users, n_movies, embedding_size = 32):\n",
    "        super().__init__()\n",
    "        # definindo embedding para clientes, produtos e categorias\n",
    "        self.users_embedding = nn.Embedding(n_users, embedding_size)\n",
    "        self.movies_embedding = nn.Embedding(n_movies, embedding_size)\n",
    "        # definindo primeira camada de reurônios totalmente conectados\n",
    "        self.fully_conn_1 = nn.Linear(embedding_size * 2, 32)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p=0.2)\n",
    "        # # # definindo primeira camada de reurônios totalmente conectados\n",
    "        self.fully_conn_2 = nn.Linear(32, 16)\n",
    "        self.relu_2 = nn.ReLU()\n",
    "        self.dropout_2 = nn.Dropout(p=0.2)\n",
    "        # definindo camada de saída como um neurônio\n",
    "        self.output_layer = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        # criando camada de entrada a partir de embeddings de clientes e produtos\n",
    "        user_embeddings = self.users_embedding(batch['users'])\n",
    "        movies_embeddings = self.movies_embedding(batch['movies'])\n",
    "        # concatenando embeddings de usuários e livros\n",
    "        concat_embeddings = torch.cat([user_embeddings, movies_embeddings], dim=1).to(torch.float32)\n",
    "        # primeira camada totalmente conectada\n",
    "        output = self.fully_conn_1(concat_embeddings)\n",
    "        output = self.relu_1(output)\n",
    "        output = self.dropout_1(output)\n",
    "        # # # segunda camada totalmente conectada\n",
    "        output = self.fully_conn_2(output)\n",
    "        output = self.relu_2(output)\n",
    "        output = self.dropout_2(output)\n",
    "        # camada de saída\n",
    "        output = self.output_layer(output)\n",
    "\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contando quantidade de clientes e produtos distintos envolvidos em compras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(610, 9724)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = df_movie_lens.n_unique_users\n",
    "n_movies = df_movie_lens.n_unique_movies\n",
    "n_users, n_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instanciando modelo RecSys, configurando otimizador, taxa de aprendizado e função custo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MovieLensRecSys(\n",
       "  (users_embedding): Embedding(610, 32)\n",
       "  (movies_embedding): Embedding(9724, 32)\n",
       "  (fully_conn_1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (dropout_1): Dropout(p=0.2, inplace=False)\n",
       "  (fully_conn_2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (relu_2): ReLU()\n",
       "  (dropout_2): Dropout(p=0.2, inplace=False)\n",
       "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MovieLensRecSys(n_users, n_movies).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2232],\n",
       "        [-0.2078],\n",
       "        [-0.1396],\n",
       "        [-0.1644]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "prev = model(batch)\n",
    "prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model, batch)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 3\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheaduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size, gamma=0.7)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando o ciclo de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 - batch:  1000 - trainig loss: 0.66836 - validation loss: 1.20138\n",
      "epoch: 1 - batch:  2000 - trainig loss: 0.40790 - validation loss: 1.12741\n",
      "epoch: 1 - batch:  3000 - trainig loss: 0.36497 - validation loss: 1.09630\n",
      "epoch: 1 - batch:  4000 - trainig loss: 0.34460 - validation loss: 1.08944\n",
      "epoch: 1 - batch:  5000 - trainig loss: 0.31966 - validation loss: 1.03694\n",
      "epoch: 1 - batch:  6000 - trainig loss: 0.30596 - validation loss: 1.02519\n",
      "epoch: 1 - batch:  7000 - trainig loss: 0.30128 - validation loss: 1.01519\n",
      "epoch: 1 - batch:  8000 - trainig loss: 0.31043 - validation loss: 1.01676\n",
      "epoch: 1 - batch:  9000 - trainig loss: 0.29561 - validation loss: 0.99600\n",
      "epoch: 1 - batch: 10000 - trainig loss: 0.27918 - validation loss: 0.99353\n",
      "epoch: 1 - batch: 11000 - trainig loss: 0.28167 - validation loss: 0.98251\n",
      "epoch: 1 - batch: 12000 - trainig loss: 0.29016 - validation loss: 0.97883\n",
      "epoch: 1 - batch: 13000 - trainig loss: 0.27906 - validation loss: 0.99621\n",
      "epoch: 1 - batch: 14000 - trainig loss: 0.27600 - validation loss: 0.96907\n",
      "epoch: 1 - batch: 15000 - trainig loss: 0.27434 - validation loss: 0.95866\n",
      "epoch: 1 - batch: 16000 - trainig loss: 0.28206 - validation loss: 0.96056\n",
      "epoch: 1 - batch: 17000 - trainig loss: 0.26206 - validation loss: 0.95520\n",
      "epoch: 2 - batch:  1000 - trainig loss: 0.41888 - validation loss: 0.94473\n",
      "epoch: 2 - batch:  2000 - trainig loss: 0.25554 - validation loss: 0.94348\n",
      "epoch: 2 - batch:  3000 - trainig loss: 0.25252 - validation loss: 0.93330\n",
      "epoch: 2 - batch:  4000 - trainig loss: 0.24940 - validation loss: 0.94662\n",
      "epoch: 2 - batch:  5000 - trainig loss: 0.25496 - validation loss: 0.93455\n",
      "epoch: 2 - batch:  6000 - trainig loss: 0.24732 - validation loss: 0.93827\n",
      "epoch: 2 - batch:  7000 - trainig loss: 0.24696 - validation loss: 0.92574\n",
      "epoch: 2 - batch:  8000 - trainig loss: 0.24631 - validation loss: 0.92540\n",
      "epoch: 2 - batch:  9000 - trainig loss: 0.23929 - validation loss: 0.91891\n",
      "epoch: 2 - batch: 10000 - trainig loss: 0.23998 - validation loss: 0.91382\n",
      "epoch: 2 - batch: 11000 - trainig loss: 0.24366 - validation loss: 0.91301\n",
      "epoch: 2 - batch: 12000 - trainig loss: 0.23464 - validation loss: 0.90626\n",
      "epoch: 2 - batch: 13000 - trainig loss: 0.24584 - validation loss: 0.90856\n",
      "epoch: 2 - batch: 14000 - trainig loss: 0.22680 - validation loss: 0.90922\n",
      "epoch: 2 - batch: 15000 - trainig loss: 0.23110 - validation loss: 0.90099\n",
      "epoch: 2 - batch: 16000 - trainig loss: 0.24027 - validation loss: 0.92100\n",
      "epoch: 2 - batch: 17000 - trainig loss: 0.23571 - validation loss: 0.91783\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "training_loss = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    for i, train_batch in enumerate(train_loader):\n",
    "        # predições do modelo (y-predito)\n",
    "        predictions = model(train_batch)\n",
    "        # calculando tamanho do lote retornado\n",
    "        batch_length = len(train_batch['ratings'])\n",
    "        # reformatando y-verdeiro para fical igual ao formato da saída do modelo (y-predito)\n",
    "        ratings = train_batch['ratings'].view(batch_length, -1).to(torch.float32)\n",
    "        # calculando o erro do modelo\n",
    "        loss = loss_function(predictions, ratings)\n",
    "        # somano erro durante o treinamento\n",
    "        training_loss += loss.sum().item()\n",
    "        # executando ajuste dos pesos no modelo via algoritmo de retropropagação\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 1000 == 999: # a cada 1000 interações de mini-lotes\n",
    "\n",
    "            validation_loss = 0.0\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            for j, validation_batch in enumerate(validation_loader):\n",
    "\n",
    "                validation_predictions = model(validation_batch)\n",
    "                # calculando tamanho do lote retornado\n",
    "                validation_batch_length = len(validation_batch['ratings'])\n",
    "                # reformatando y-verdeiro para fical igual ao formato da saída do modelo (y-predito)\n",
    "                validation_ratings = validation_batch['ratings'].view(validation_batch_length, -1).to(torch.float32)\n",
    "                # calculando o erro do modelo\n",
    "                val_loss = loss_function(validation_predictions, validation_ratings)\n",
    "                # somando erro de validaçao\n",
    "                validation_loss += val_loss.sum().item()\n",
    "\n",
    "            model.train()\n",
    "\n",
    "            avg_training_loss = training_loss / (batch_length * 1000)\n",
    "            avg_validation_loss = validation_loss / len(validation_loader)\n",
    "\n",
    "            print('epoch: %d - batch: %5d - trainig loss: %.5f - validation loss: %.5f' % (epoch + 1, i + 1, avg_training_loss, avg_validation_loss))\n",
    "\n",
    "            writer.add_scalars(\n",
    "                main_tag='Training vs. Validation Loss',\n",
    "                tag_scalar_dict={\n",
    "                    'Training': avg_training_loss,\n",
    "                    'Validation': avg_validation_loss\n",
    "                },\n",
    "                global_step=epoch * len(train_loader) + i\n",
    "            )\n",
    "\n",
    "            training_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './model/MovieLensRecSys.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaliando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MovieLensRecSys(\n",
       "  (users_embedding): Embedding(610, 32)\n",
       "  (movies_embedding): Embedding(9724, 32)\n",
       "  (fully_conn_1): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (dropout_1): Dropout(p=0.2, inplace=False)\n",
       "  (fully_conn_2): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (relu_2): ReLU()\n",
       "  (dropout_2): Dropout(p=0.2, inplace=False)\n",
       "  (output_layer): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(model_path, weights_only=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculando a raiz do erro quadrádico médio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4887937781491371"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "model_output_list = []\n",
    "target_rating_list = []\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for index, test_data in enumerate(test_loader):\n",
    "        # calculando tamanho do lote retornado\n",
    "        batch_length = len(test_data['ratings'])\n",
    "        # predições do modelo (y-predito)\n",
    "        output = model(test_data)\n",
    "        # armazenando o erro do modelo\n",
    "        model_output_list.append(output.sum().item() / batch_length)\n",
    "        # recuperando valor original (y-verdadeiro)\n",
    "        target_rating = test_data['ratings']\n",
    "        target_rating_list.append(target_rating.sum().item() / batch_length)\n",
    "\n",
    "rms = root_mean_squared_error(target_rating_list, model_output_list)\n",
    "rms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "old: 0.49067842992108573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "precisão e recall dos K-produtos (Precision@K and Recall@K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "users_pred_true = defaultdict(list)\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for i, test_data in enumerate(test_loader):\n",
    "\n",
    "        users = test_data['users']\n",
    "        movies = test_data['movies']\n",
    "        ratings = test_data['ratings']\n",
    "\n",
    "        output = model(test_data)\n",
    "\n",
    "        for j in range(len(users)):\n",
    "\n",
    "            user_id = users[j].item()\n",
    "            book_id = movies[j].item()\n",
    "\n",
    "            pred_ratings = output[j][0].item()\n",
    "            true_ratings = ratings[j].item()\n",
    "\n",
    "            users_pred_true[user_id].append((pred_ratings, true_ratings))\n",
    "\n",
    "            # print(f'customer_id: {user_id}; product_id: {book_id}; true_ratings: {true_ratings}; pred_ratings: {pred_ratings}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "\n",
    "    k=100\n",
    "    threshold=3.0\n",
    "\n",
    "    for uid, user_pred_true in users_pred_true.items():\n",
    "\n",
    "        # ordenando as predições de filmes comprados por cliente\n",
    "        user_pred_true.sort(key=lambda x: x[0], reverse=True)\n",
    "        # registrando o número de filmes relevantes\n",
    "        n_rel = sum((true_p >= threshold) for (_, true_p) in user_pred_true)\n",
    "        # regitrando o número de filmes recomendados que foram preditos como relevantes para o top K filmes\n",
    "        n_rec_k = sum((pred >= threshold) for (pred, _) in user_pred_true[:k])\n",
    "        # registrando o número de filmes recomendados que são realmente relevantes para o top K filmes\n",
    "        n_rec_and_rec_k = sum(\n",
    "            ((true_p >= threshold) and (pred >= threshold))\n",
    "            for (pred, true_p) in user_pred_true[:k]\n",
    "        )\n",
    "\n",
    "        # print(f'uid: {uid}; n_rel: {n_rel}; n_rec_k: {n_rec_k}; n_rec_and_rec_k: {n_rec_and_rec_k}')\n",
    "\n",
    "        # proporção de filmes recomendados que são relevantes\n",
    "        precisions[uid] = n_rec_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        # proporção de filmes relevantes que foram recomendados\n",
    "        recalls[uid] = n_rec_and_rec_k / n_rel if n_rel != 0 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@100: 0.862348823033688\n",
      "Recall@100: 0.9074978974828789\n"
     ]
    }
   ],
   "source": [
    "print(f'Precision@{k}: {sum(prec for prec in precisions.values()) / len(precisions)}')\n",
    "print(f'Recall@{k}: {sum(rec for rec in recalls.values()) / len(recalls)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigando embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_movies = np.unique(df_movie_lens.movies)\n",
    "sample_movies = np.random.choice(unique_movies, size=1000, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_movies_tensor = torch.from_numpy(sample_movies)\n",
    "\n",
    "with torch.no_grad():\n",
    "    movies_embeddings = model.movies_embedding(movies_movies_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_movies_ids = df_movie_lens.get_original_movie_id(sample_movies)\n",
    "df_movies = pd.read_csv('./data/movie-lens/raw/movies.csv')\n",
    "movies_genres = df_movies.loc[df_movies['movieId'].isin(sample_movies_ids), 'genres'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "writer.add_embedding(\n",
    "    mat=movies_embeddings,\n",
    "    metadata=movies_genres\n",
    ")\n",
    "writer.flush()\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
